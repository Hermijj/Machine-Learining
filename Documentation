# Olympic Medals Prediction Project Report

**Debre Birhan University**  
*College of Computing, Department of Software Engineering*  
*Fundamentals of Machine Learning*

**Name:** Hermela Gashaw  
**ID:** 1401389  
**Submitted to:** Seble E  
**Submission Date:** 02/02/2025  

---

## 1. Problem Definition

### Objective
Predict the number of medals an Olympic team will win based on historical performance data. This problem is approached as a regression task, with the number of medals being the target variable.

### Motivation
Understanding which factors contribute to a team’s success can help in strategizing and resource allocation. In this project, we focus on two key predictors:

- **Athletes:** The number of athletes on a team.
- **Previous Medals:** The count of medals won in prior events.

---

## 2. Data Source & Description

### Data Source
We'll be using data from the Olympics, originally sourced from [Kaggle](https://www.kaggle.com/datasets/heesoo37/120-years-of-olympic-history-athletes-and-results).

You can download the files for this project here:

- [teams.csv](https://drive.google.com/uc?export=download&id=1L3YAlts8tijccIndVPB-mOsRpEpVawk7) — the team-level data used in this project.

### Dataset Description
The dataset is in CSV format and includes the following columns:

- **team:** Name of the team.
- **country:** Country that the team represents.
- **year:** Year of the Olympic event.
- **athletes:** Number of athletes in the team.
- **age:** Average age of the athletes.
- **prev_medals:** Number of medals won in previous events.
- **medals:** Number of medals won in the current event (target variable).

### Dataset Overview
- **2144 rows and 11 columns**
- **Columns:**
  - `team` (string): Team name
  - `country` (string): Country name
  - `year` (integer): Year of participation
  - `events` (integer): Number of events participated in
  - `athletes` (integer): Number of athletes in the team
  - `age` (float): Average age of athletes
  - `height` (float): Average height of athletes
  - `weight` (float): Average weight of athletes
  - `medals` (integer): Number of medals won
  - `prev_medals` (float, some missing values): Medals won in the previous year
  - `prev_3_medals` (float, some missing values): Medals won in the last 3 years

---

## 3. Exploratory Data Analysis (EDA) Findings and Visualizations

### Data Loading & Inspection
- The dataset was loaded into a pandas DataFrame.
- Initial inspection revealed the structure and distribution of the data, including some missing values.

### Summary Statistics
- Statistical summaries (mean, median, standard deviation) were computed for all numeric columns.
- These summaries provided insights into the central tendency and spread of the data.

### Correlation Analysis
- A correlation matrix was computed for the numeric variables.
- The analysis revealed that the number of athletes and `prev_medals` have significant correlations with the target variable `medals`.

### Visualizations
- **Scatter Plots with Regression Lines:**
  - Used `seaborn.lmplot` to visualize the relationships between `athletes` and `medals`, and between `age` and `medals`.

- **Histogram:**
  - Plotted the distribution of the `medals` variable to assess its distribution.

These EDA steps helped identify key trends and potential outliers in the data.

---

## 4. Data Preprocessing Steps and Choices

### Conversion and Cleaning
- **Numeric Conversion:**
  - Applied `pd.to_numeric` to convert columns to numeric types wherever possible.
  - Dropped non-numeric columns that became entirely NaN after conversion.

- **Handling Missing Values:**
  - Identified rows with missing values using `teams[teams.isnull().any(axis=1)]`.
  - Removed rows containing missing values to ensure data quality.

### Feature Selection
- For model training, the selected predictors were:
  - `athletes`
  - `prev_medals`
- The target variable was `medals`.

### Train-Test Split
- Data was split 80% into training and 20% into testing sets based on the year:
  - **Training set:** `year < 2012`
  - **Testing set:** `year >= 2012`

### Post-Prediction Adjustments
- Negative predictions (if any) were set to zero.
- Predictions were rounded to the nearest whole number to match the nature of the target variable.

---

## 5. Model Selection and Training Details

### Model Choice
For this project, we chose a **linear regression** model because the problem involves predicting a numerical outcome (the number of medals won). The reasons include:

1. **Nature of the Target Variable:**
   - The target variable, `medals`, represents a count of medals won by a team. It is treated as a continuous variable in the context of prediction.

2. **Relationship Between Predictors and Outcome:**
   - EDA revealed linear relationships between predictors (`athletes`, `prev_medals`) and the target variable.

3. **Simplicity and Interpretability:**
   - Linear regression provides interpretable coefficients that indicate how changes in predictors influence medal counts.

4. **Suitability to the Data Structure:**
   - The structured numerical data fits well with a regression approach.

### Model Training
Run the data preprocessing and model training script (e.g., in a Jupyter Notebook or Python script) to generate `linear_regression_model.pkl`.

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()

predictors = ["athletes", "prev_medals"]
reg.fit(train[predictors], train["medals"])
```

### Prediction
```python
predictions = reg.predict(test[predictors])
test["predictions"] = predictions
```

---

## 6. Model Evaluation Metrics and Discussion

### Evaluation Metrics
- **Mean Absolute Error (MAE):** Measures the average absolute difference between predicted and actual values.
- **Root Mean Squared Error (RMSE):** The square root of the average squared differences; provides insight into prediction error magnitude.
- **R² Score:** Indicates the proportion of variance in the target variable explained by the model.

### Metric Calculation
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

mae = mean_absolute_error(test["medals"], test["predictions"])
rmse = np.sqrt(mean_squared_error(test["medals"], test["predictions"]))
r2 = r2_score(test["medals"], test["predictions"])

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"R² Score: {r2:.4f}")
```

### Discussion
- The evaluation metrics provide a clear understanding of how close the predictions are to the actual values.
- Error analysis per team was also performed, where the average prediction error was calculated and analyzed relative to the mean medals per team.
- Visualizations (histograms) of the error distribution were used to assess model performance.

---

## 7. Interpretation of Results

### Key Insights
- The predictors `athletes` and `prev_medals` significantly contribute to the prediction of `medals`.
- The model achieves a reasonable fit, as indicated by the R² score.
- The error analysis suggests that while the model performs well overall, some teams exhibit higher prediction errors, possibly due to factors not captured by the current features.

### Implications
- The linear regression model provides a straightforward approach for predicting Olympic medals based on historical data.
- The insights can help in identifying areas for further feature engineering or model complexity enhancements.

---

## 8. Deployment Details and Instructions

### API Deployment with FastAPI
The model has been deployed as an API using **FastAPI**, allowing users to obtain predictions via HTTP requests.

### API Endpoints
- **GET /**: Returns a welcome message along with usage instructions.
- **POST /predict/**: Accepts a JSON payload with the following fields: `team`, `country`, `year`, `athletes`, `age`, and `prev_medals`. Returns the predicted number of medals along with the input details.

### Running the API
1. **Install Dependencies:**
    ```bash
    pip install fastapi uvicorn joblib pandas numpy scikit-learn
    ```
2. **Start the API:**
    ```bash
    uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ```
3. **Access the API Documentation:**
    - Navigate to [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) for interactive API documentation and testing.

### API Code Overview (`main.py`)
```python
from fastapi import FastAPI
import joblib
import pandas as pd
from pydantic import BaseModel

# Load the trained model
model = joblib.load("linear_regression_model.pkl")

app = FastAPI(
    title="Olympic Medals Prediction API",
    description="Predict the number of medals a team will win based on key features.",
    version="1.0"
)

class MedalsInput(BaseModel):
    team: str
    country: str
    year: int
    athletes: int
    age: float
    prev_medals: float

@app.get("/")
def welcome():
    return {"message": "Welcome to the Olympic Medals Prediction API! Use /predict/ to get medal predictions."}

@app.post("/predict/")
def predict_medals(data: MedalsInput):
    try:
        input_data = pd.DataFrame([data.dict()])
        predictors = ["athletes", "prev_medals"]
        prediction = model.predict(input_data[predictors])[0]
        prediction = max(0, round(prediction))  # Ensure non-negative integer output
        return {
            "message": "Prediction successful!",
            "team": data.team,
            "country": data.country,
            "year": data.year,
            "predicted_medals": prediction
        }
    except Exception as e:
        return {"error": "Prediction failed. Please check your input data.", "details": str(e)}
```

---

## 9. Potential Limitations and Future Improvements

### Limitations
- **Feature Selection:** Only two predictors (`athletes` and `prev_medals`) were used. Additional features like team budget or training facilities might enhance the model.
- **Model Complexity:** The linear regression model may not capture complex nonlinear relationships in the data.

### Future Improvements
- **Data Enrichment:** Incorporate more features or external data sources that may influence a team's performance.
- **Advanced Modeling:** Explore more complex models (e.g., ensemble methods, neural networks) to potentially improve prediction accuracy.
- **Feature Engineering:** Implement feature scaling, interaction terms, or polynomial features to capture nonlinear trends.
- **API Enhancements:** Add endpoints for model retraining, logging, and detailed error reporting.
- **User Interface:** Develop a simple front-end application for easier interaction with the API.

---

## 10. References

- ML Individual Assignment Guidelines
- [pandas Documentation](https://pandas.pydata.org/docs/)
- [scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

---

